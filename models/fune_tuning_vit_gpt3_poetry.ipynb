{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1WK9q4TG1TTm2FYJgTOAFw8hHG8Dw3Zna?usp=sharing)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "p4Ng0-lJgs9T"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A7DANZiDep2y"
      },
      "source": [
        "## Fix device issues"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-S-UqLSqespp"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HYQgcML1fVCZ"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QDo5iYDpfX0c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ee92cd0-697f-4107-90a1-db4b8585c758"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Quadro RTX 6000'"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "torch.cuda.get_device_name(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bve2yDLXnNdJ"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40SCLp73jClM"
      },
      "source": [
        "#1. get dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7pMfpxOEVenX"
      },
      "outputs": [],
      "source": [
        "# !pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PgOpr0KAOtLN",
        "outputId": "ad1b022c-a3f3-463b-9b23-db652c072cbe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/home/revolt/anaconda3/envs/poetry_gpt3_large/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "Found cached dataset parquet (/home/revolt/.cache/huggingface/datasets/AnyaSchen___parquet/AnyaSchen--image2poetry_ru-bd53c8b353e828ac/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
            "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 332.09it/s]\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "data_train = load_dataset(\"AnyaSchen/image2poetry_ru\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CIO0As6RVbjJ"
      },
      "outputs": [],
      "source": [
        "data = data_train['train']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-9pnxd49i_9C"
      },
      "source": [
        "# 2. Preprocess the dataset: \n",
        "\n",
        "Preprocess the images and poetry text for training. For images, you can use the same preprocessing method as the CLIP processor. For text, you can tokenize the poetry using a Russian GPT model tokenizer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y8FiFo19A1Xm",
        "outputId": "6f932469-2666-43bc-9f3a-e2c56c72e975"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 224, 224])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n"
          ]
        }
      ],
      "source": [
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "from torch.utils.data import Dataset\n",
        "from transformers import ViTImageProcessor, AutoTokenizer\n",
        "\n",
        "class ImagePoetryDataset(Dataset):\n",
        "    def __init__(self, dataset, vit_image_processor, tokenizer):\n",
        "        self.dataset = dataset\n",
        "        self.vit_image_processor = vit_image_processor\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Load and preprocess the image\n",
        "        image = self.dataset[idx]['image'].convert(\"RGB\")\n",
        "        inputs = self.vit_image_processor(images=image, return_tensors=\"pt\", padding=True)\n",
        "        pixel_values = inputs[\"pixel_values\"].squeeze(0)\n",
        "\n",
        "        # Concatenate author and poetry with separator\n",
        "        text = f\"<bos> {self.dataset[idx]['author']} <sep> {self.dataset[idx]['poetry']} <eos>\"\n",
        "\n",
        "        # Tokenize the combined text\n",
        "        tokens = self.tokenizer(text, return_tensors=\"pt\", padding=\"max_length\", max_length=128, truncation=True)\n",
        "        input_ids = tokens[\"input_ids\"].squeeze(0)\n",
        "        attention_mask = tokens[\"attention_mask\"].squeeze(0)\n",
        "\n",
        "        # Copy the input IDs to use as labels\n",
        "        labels = input_ids.clone()\n",
        "\n",
        "        return {\n",
        "            \"pixel_values\": pixel_values,\n",
        "            \"input_ids\": input_ids,\n",
        "            \"attention_mask\": attention_mask,\n",
        "            'labels': labels\n",
        "        }\n",
        "\n",
        "\n",
        "# Load the CLIP processor\n",
        "# clip_processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
        "vit_image_processor = ViTImageProcessor.from_pretrained(\"google/vit-base-patch16-224-in21k\")\n",
        "\n",
        "# Load a GPT tokenizer for the Russian language\n",
        "tokenizer = AutoTokenizer.from_pretrained('ai-forever/rugpt3medium_based_on_gpt2')\n",
        "\n",
        "SPECIAL_TOKENS = {'bos_token': \"<bos>\", \"eos_token\": \"<eos>\", 'pad_token': '<pad>', 'sep_token': '<sep>'}\n",
        "tokenizer.add_special_tokens(SPECIAL_TOKENS)\n",
        "# Create the Dataset\n",
        "dataset = ImagePoetryDataset(data, vit_image_processor, tokenizer)\n",
        "\n",
        "# Example usage\n",
        "sample = dataset[0]\n",
        "print(sample[\"pixel_values\"].shape)  # Processed image tensor\n",
        "print(sample[\"input_ids\"].shape)  # Tokenized poetry input IDs\n",
        "print(sample[\"attention_mask\"].shape)  # Tokenized poetry attention mask\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8vZJ0nKjFOp"
      },
      "source": [
        "#3. Fine-tune the model: \n",
        "\n",
        "Fine-tune a vision-language model using the preprocessed dataset. You can use a pre-trained VisionEncoderDecoder model from Hugging Face as a starting point, and then fine-tune it on your custom dataset. This way, the model will learn the relationship between the images and the corresponding poetry."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "60mpz2P6jHBl"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from transformers import VisionEncoderDecoderModel, VisionEncoderDecoderConfig, TrainingArguments, Trainer\n",
        "\n",
        "# Create a new VisionEncoderDecoder model with the config\n",
        "model = VisionEncoderDecoderModel.from_pretrained(\"tuman/vit-rugpt2-image-captioning\")\n",
        "model.to(device)\n",
        "model.decoder.resize_token_embeddings(len(tokenizer))\n",
        "model.config.decoder_start_token_id = tokenizer.bos_token_id\n",
        "model.config.pad_token_id = tokenizer.pad_token_id\n",
        "\n",
        "# Split the dataset into train and validation sets (80-20 split)\n",
        "train_size = int(0.99 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "# Create data loaders\n",
        "batch_size = 3\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
        "\n",
        "# Define the training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./checkouts\",\n",
        "    num_train_epochs=27,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    gradient_accumulation_steps=10,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    logging_dir=\"./image_poetry_logs\",\n",
        "    save_steps = 1000,\n",
        "    learning_rate=3e-5,\n",
        "    weight_decay=0.01,\n",
        "    # fp16=True,  # Use mixed precision training if possible (requires an NVIDIA GPU with Tensor Cores)\n",
        ")\n",
        "\n",
        "# Create a Trainer instance\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()\n",
        "\n",
        "model.save_pretrained('./model')\n",
        "tokenizer.save_pretrained('./tokenizer')\n",
        "vit_image_processor.save_pretrained('./processor')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mDop_CDHUAyG"
      },
      "source": [
        "##load to hugging face"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cyUbSs4NTuyw",
        "outputId": "1e91270c-32f7-41ab-f91b-3b022694c763"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: huggingface_hub in /home/revolt/anaconda3/envs/poetry_gpt3_large/lib/python3.9/site-packages (0.14.1)\n",
            "Requirement already satisfied: requests in /home/revolt/anaconda3/envs/poetry_gpt3_large/lib/python3.9/site-packages (from huggingface_hub) (2.29.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/revolt/anaconda3/envs/poetry_gpt3_large/lib/python3.9/site-packages (from huggingface_hub) (4.5.0)\n",
            "Requirement already satisfied: filelock in /home/revolt/anaconda3/envs/poetry_gpt3_large/lib/python3.9/site-packages (from huggingface_hub) (3.9.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /home/revolt/anaconda3/envs/poetry_gpt3_large/lib/python3.9/site-packages (from huggingface_hub) (23.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /home/revolt/anaconda3/envs/poetry_gpt3_large/lib/python3.9/site-packages (from huggingface_hub) (6.0)\n",
            "Requirement already satisfied: fsspec in /home/revolt/anaconda3/envs/poetry_gpt3_large/lib/python3.9/site-packages (from huggingface_hub) (2023.5.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /home/revolt/anaconda3/envs/poetry_gpt3_large/lib/python3.9/site-packages (from huggingface_hub) (4.65.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/revolt/anaconda3/envs/poetry_gpt3_large/lib/python3.9/site-packages (from requests->huggingface_hub) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/revolt/anaconda3/envs/poetry_gpt3_large/lib/python3.9/site-packages (from requests->huggingface_hub) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/revolt/anaconda3/envs/poetry_gpt3_large/lib/python3.9/site-packages (from requests->huggingface_hub) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /home/revolt/anaconda3/envs/poetry_gpt3_large/lib/python3.9/site-packages (from requests->huggingface_hub) (2.0.4)\n",
            "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
            "Token is valid.\n",
            "Your token has been saved to /home/revolt/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ],
      "source": [
        "!pip install huggingface_hub\n",
        "!huggingface-cli login --token {auth_token}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ou2ynJGjTMnx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d05ea56-927a-4232-be68-ea46199d11d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "pytorch_model.bin: 100%|█████████████████████████████████████████████████| 4.30G/4.30G [10:29<00:00, 6.83MB/s]\n",
            "\n",
            "Upload 1 LFS files: 100%|██████████████████████████████████████████████████████| 1/1 [10:30<00:00, 630.29s/it]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CommitInfo(commit_url='https://huggingface.co/AnyaSchen/vit-rugpt3-large-poetry-ft/commit/9e4a00999612f9cd4b5f1d1ce979aea76ba46a95', commit_message='Upload feature extractor', commit_description='', oid='9e4a00999612f9cd4b5f1d1ce979aea76ba46a95', pr_url=None, pr_revision=None, pr_num=None)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "fine_tuned_model.push_to_hub('AnyaSchen/vit-rugpt3-large-poetry-ft')\n",
        "tokenizer.push_to_hub('AnyaSchen/vit-rugpt3-large-poetry-ft')\n",
        "feature_extractor.push_to_hub('AnyaSchen/vit-rugpt3-large-poetry-ft')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0sOFxKWcjtdi"
      },
      "source": [
        "#4.Generation "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "device = torch.device('cuda')"
      ],
      "metadata": {
        "id": "_hckrYIUDWN7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NoKoiIYjjvaM"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import requests\n",
        "from transformers import AutoTokenizer, CLIPProcessor, VisionEncoderDecoderModel, ViTFeatureExtractor\n",
        "\n",
        "def generate_poetry(fine_tuned_model, image, tokenizer, author):\n",
        "    # Preprocess the image using the CLIP processor\n",
        "    pixel_values = feature_extractor(images=image, return_tensors=\"pt\").pixel_values\n",
        "    pixel_values = pixel_values.to(device)\n",
        "    \n",
        "    # Encode author's name and prepare as input to the decoder\n",
        "    author_input = f\"<bos> {author} <sep>\"\n",
        "    decoder_input_ids = tokenizer.encode(author_input, return_tensors=\"pt\").to(device)\n",
        "\n",
        "    # Generate the poetry with the fine-tuned VisionEncoderDecoder model\n",
        "    generated_tokens = fine_tuned_model.generate(\n",
        "        pixel_values,\n",
        "        decoder_input_ids=decoder_input_ids,\n",
        "        max_length=300,\n",
        "        num_beams=3,\n",
        "        top_p=0.8,\n",
        "        temperature=2.0,\n",
        "        do_sample=True,\n",
        "        pad_token_id=tokenizer.pad_token_id,\n",
        "        eos_token_id=tokenizer.eos_token_id,\n",
        "    )\n",
        "\n",
        "    # Decode the generated tokens\n",
        "    generated_poetry = tokenizer.decode(generated_tokens[0], skip_special_tokens=True)\n",
        "    return generated_poetry\n",
        "\n",
        "\n",
        "# Load the fine-tuned model\n",
        "fine_tuned_model = VisionEncoderDecoderModel.from_pretrained(\"AnyaSchen/vit-rugpt3-large-poetry-ft\")\n",
        "feature_extractor = ViTFeatureExtractor.from_pretrained(\"AnyaSchen/vit-rugpt3-large-poetry-ft\")\n",
        "\n",
        "# Load a GPT tokenizer for the Russian language\n",
        "tokenizer = AutoTokenizer.from_pretrained('AnyaSchen/vit-rugpt3-large-poetry-ft')\n",
        "fine_tuned_model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'https://gamerwall.pro/uploads/posts/2022-07/1657962598_1-gamerwall-pro-p-grustnaya-zima-oboi-1.jpg'\n",
        "# Test with a new image\n",
        "image = Image.open(requests.get(url, stream=True).raw)\n",
        "# Generate poetry based on the input image\n",
        "generated_poetry = generate_poetry(fine_tuned_model, image, tokenizer, 'Пушкин')\n",
        "print(generated_poetry)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8TJaDuI_INFa",
        "outputId": "2b17ba78-926e-4d87-e55b-5eef4056196a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Пушкин Метель серебрится,\n",
            "Немолчный звук,\n",
            "То отголосок прежних дней\n",
            "Серебрится в лунном сияньи.\n",
            "Умчались, умчалися прочь\n",
            "Все счастливые дни моей жизни,\n",
            "И сердце остыло, и ум холодный\n",
            "Страшен мне.\n",
            "Брожу один, и в лунном сияньи\n",
            "Мне вспомнилась прежняя жизнь,\n",
            "Метель серебристится,\n",
            "Немолчный звук...\n",
            "Отчего ты, любовь моя,\n",
            "Так грустна и так уныла?\n",
            " \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TU5-BoMC54Hu"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuClass": "premium"
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}