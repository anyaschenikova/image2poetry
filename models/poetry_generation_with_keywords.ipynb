{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1ZXourEIpzByuA5YpUTxyOBic_pNt0htu?usp=sharing)\n"
      ],
      "metadata": {
        "id": "cchtVn_agX7H"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QByyuFm4gy_D"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d8fP5y2Ipsln"
      },
      "outputs": [],
      "source": [
        "# !pip install transformers==4.19.0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Clear GPU memory\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "# Check available memory\n",
        "print(torch.cuda.memory_summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63DrD0CQuJy2",
        "outputId": "f5762378-c931-4595-d787-bb7bd47441c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "|===========================================================================|\n",
            "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
            "|---------------------------------------------------------------------------|\n",
            "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
            "|===========================================================================|\n",
            "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |\n",
            "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
            "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |\n",
            "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
            "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |\n",
            "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
            "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |\n",
            "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
            "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |\n",
            "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
            "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocations           |       0    |       0    |       0    |       0    |\n",
            "|       from large pool |       0    |       0    |       0    |       0    |\n",
            "|       from small pool |       0    |       0    |       0    |       0    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active allocs         |       0    |       0    |       0    |       0    |\n",
            "|       from large pool |       0    |       0    |       0    |       0    |\n",
            "|       from small pool |       0    |       0    |       0    |       0    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved segments |       0    |       0    |       0    |       0    |\n",
            "|       from large pool |       0    |       0    |       0    |       0    |\n",
            "|       from small pool |       0    |       0    |       0    |       0    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable allocs |       0    |       0    |       0    |       0    |\n",
            "|       from large pool |       0    |       0    |       0    |       0    |\n",
            "|       from small pool |       0    |       0    |       0    |       0    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
            "|===========================================================================|\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0lhkuNdOoqvq"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O6ujFUYBl2Fj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 537
        },
        "outputId": "34cef9e7-2f2c-45d4-a0c7-bec6e86c106f"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/accelerate/tracking.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorboard\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mModuleNotFoundError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/utils/tensorboard/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mwriter\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFileWriter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSummaryWriter\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorboard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_writer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRecordWriter\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/utils/tensorboard/writer.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorboard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorboard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevent_pb2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSessionLog\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorboard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevent_pb2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEvent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorboard/compat/proto/event_pb2.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\"\"\"Generated protocol buffer code.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotobuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minternal\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0menum_type_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotobuf\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdescriptor\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_descriptor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.protobuf'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m_get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1171\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1172\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1173\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/lib/python3.9/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/lib/python3.9/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/lib/python3.9/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/lib/python3.9/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/lib/python3.9/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/lib/python3.9/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/lib/python3.9/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m )\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0mmodeling_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPreTrainedModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSequenceSummary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0mpytorch_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConv1D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfind_pruneable_heads_and_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprune_conv1d_layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_accelerate_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0maccelerate\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__version__\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0maccelerate_version\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0maccelerate\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdispatch_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfer_auto_device_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_empty_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/accelerate/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAccelerator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m from .big_modeling import (\n",
            "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/accelerate/accelerator.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAcceleratorState\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGradientState\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPartialState\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparse_flag_from_env\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtracking\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLOGGER_TYPE_TO_CLASS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGeneralTracker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter_trackers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m from .utils import (\n",
            "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/accelerate/tracking.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mModuleNotFoundError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0;32mimport\u001b[0m \u001b[0mtensorboardX\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtensorboard\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorboardX/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mrecord_writer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRecordWriter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtorchvis\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTorchVis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mwriter\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFileWriter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSummaryWriter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorboardX/torchvis.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfunctools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwraps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mwriter\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSummaryWriter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mvisdom_writer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVisdomWriter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorboardX/writer.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcomet_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCometLogger\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmake_mat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmake_sprite\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmake_tsv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappend_pbtxt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorboardX/comet_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mio\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotobuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson_format\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMessageToJson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.protobuf'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_1466/3699346066.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGPT2LMHeadModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataset\u001b[0m \u001b[0;31m# this is the pytorch class import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataCollatorForLanguageModeling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTrainingArguments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/lib/python3.9/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1161\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1162\u001b[0m             \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1163\u001b[0;31m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1164\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1165\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"module {self.__name__} has no attribute {name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1160\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1161\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1162\u001b[0;31m             \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1163\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1164\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m_get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1172\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1173\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1174\u001b[0;31m             raise RuntimeError(\n\u001b[0m\u001b[1;32m   1175\u001b[0m                 \u001b[0;34mf\"Failed to import {self.__name__}.{module_name} because of the following error (look up to see its\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m                 \u001b[0;34mf\" traceback):\\n{e}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Failed to import transformers.models.gpt2.modeling_gpt2 because of the following error (look up to see its traceback):\nNo module named 'google.protobuf'"
          ]
        }
      ],
      "source": [
        "from transformers import GPT2LMHeadModel, AutoTokenizer\n",
        "import torch\n",
        "from torch.utils.data import Dataset # this is the pytorch class import\n",
        "from transformers import DataCollatorForLanguageModeling\n",
        "from transformers import TrainingArguments, Trainer\n",
        "from transformers import StoppingCriteria, StoppingCriteriaList"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.get_device_name(0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Cpkcc5PzJ5t",
        "outputId": "cd11c814-f5c2-4ed0-e6d3-bb09c3a0a0f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'NVIDIA GeForce RTX 3080 Ti'"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DEVICE = torch.device(\"cuda:0\") if torch.cuda.is_available() else None"
      ],
      "metadata": {
        "id": "BJJiLD9f12sK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.current_device()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hG5j5wyD0OLU",
        "outputId": "2ee2601e-6893-4c58-c4b7-fda02c663124"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TXm1tO7SrWlr"
      },
      "outputs": [],
      "source": [
        "model_sber = 'ai-forever/rugpt3medium_based_on_gpt2'\n",
        "model_mayak = 'AnyaSchen/rugpt3_mayakovskij'\n",
        "my_path = '/'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZHj1iHLGwakX"
      },
      "source": [
        "# Install model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ha9HPro0eQWm",
        "outputId": "6506d011-e413-4a9d-c259-4ea1eb9cb93b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading (…)lve/main/config.json: 100%|███████████████████████████████████████████████████████████| 674/674 [00:00<00:00, 194kB/s]\n",
            "Downloading (…)olve/main/vocab.json: 100%|██████████████████████████████████████████████████████| 1.61M/1.61M [00:00<00:00, 3.15MB/s]\n",
            "Downloading (…)olve/main/merges.txt: 100%|██████████████████████████████████████████████████████| 1.27M/1.27M [00:00<00:00, 2.44MB/s]\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "Downloading pytorch_model.bin: 100%|████████████████████████████████████████████████████████████| 1.73G/1.73G [03:01<00:00, 9.55MB/s]\n"
          ]
        }
      ],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_sber)\n",
        "model = GPT2LMHeadModel.from_pretrained(model_sber).to(DEVICE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wLb38E6KMYs2"
      },
      "source": [
        "# Fine-tuning step-by-step"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w11Hq5Lvwcdu"
      },
      "source": [
        "## Add special tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ImM0Aq0dE8q"
      },
      "outputs": [],
      "source": [
        "SPECIAL_TOKENS = {'bos_token' : \"<bos>\", \"eos_token\" :\"<eos>\", 'pad_token':'<pad>'}\n",
        "tokenizer.add_special_tokens(SPECIAL_TOKENS)\n",
        "model.resize_token_embeddings(len(tokenizer))\n",
        "model.config.bos_token_id = tokenizer.bos_token_id"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ujRlaYGkwgtV"
      },
      "source": [
        "## Get data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Md8LLYKrdYzz",
        "outputId": "e3f3bd0f-6b19-4a63-8fd5-78c97740ef28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-05-13 19:35:37--  https://www.dropbox.com/s/neb74j04nfxay14/poetry_keywords.csv?dl=0\r\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.71.18, 205.251.194.52, 205.251.199.157, ...\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.71.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /s/raw/neb74j04nfxay14/poetry_keywords.csv [following]\n",
            "--2023-05-13 19:35:37--  https://www.dropbox.com/s/raw/neb74j04nfxay14/poetry_keywords.csv\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://ucd18937b93694b8e97bc7191eff.dl.dropboxusercontent.com/cd/0/inline/B79r4uwFkhMxf_1SzLlLEWsYV-wI2qiG_gt7XOxM-MGxWKmtjnkBMAB9K9z7CuWSGpu_4rQTwJ-VzpC0C3LHQ4wa1_ucnW7gslwnsz99LRK2NExxa2ms4jDseHzJGdcMUNBKEzlaoyY3wjMjaZAH3N4NBWOe7tbqsEM3iauCBjjLgA/file# [following]\n",
            "--2023-05-13 19:35:38--  https://ucd18937b93694b8e97bc7191eff.dl.dropboxusercontent.com/cd/0/inline/B79r4uwFkhMxf_1SzLlLEWsYV-wI2qiG_gt7XOxM-MGxWKmtjnkBMAB9K9z7CuWSGpu_4rQTwJ-VzpC0C3LHQ4wa1_ucnW7gslwnsz99LRK2NExxa2ms4jDseHzJGdcMUNBKEzlaoyY3wjMjaZAH3N4NBWOe7tbqsEM3iauCBjjLgA/file\n",
            "Resolving ucd18937b93694b8e97bc7191eff.dl.dropboxusercontent.com (ucd18937b93694b8e97bc7191eff.dl.dropboxusercontent.com)... 162.125.71.15, 162.125.71.15, 2620:100:6026:15::a27d:460f\n",
            "Connecting to ucd18937b93694b8e97bc7191eff.dl.dropboxusercontent.com (ucd18937b93694b8e97bc7191eff.dl.dropboxusercontent.com)|162.125.71.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4039565 (3.9M) [text/plain]\n",
            "Saving to: ‘data_keywords.csv’\n",
            "\n",
            "data_keywords.csv   100%[===================>]   3.85M  5.41MB/s    in 0.7s    \n",
            "\n",
            "2023-05-13 19:35:39 (5.41 MB/s) - ‘data_keywords.csv’ saved [4039565/4039565]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://www.dropbox.com/s/neb74j04nfxay14/poetry_keywords.csv?dl=0 -O poetry_keywords.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WXeiVp4TdeGK"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "dataset = pd.read_csv('poetry_keywords.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DejAhD7dwjwX"
      },
      "source": [
        "## Greate a Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vKsDqthMdxna"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(42) # this is the pytorch class import\n",
        "\n",
        "class myDataset(Dataset):\n",
        "\n",
        "  def __init__(self, data: pd.DataFrame, tokenizer, gpt2_type=\"gpt2\", max_length=150):\n",
        "\n",
        "    self.tokenizer = tokenizer # the gpt2 tokenizer we instantiated\n",
        "    self.input_ids = []\n",
        "    self.attn_masks = []\n",
        "\n",
        "    for ind in data.index:\n",
        "\n",
        "      author = 'Автор:' + data.iloc[ind]['author']\n",
        "      keywords = 'Ключевые слова: ' + ', '.join(data.iloc[ind]['keywords'].split(\"'\")[1:-1:2])+ '\\n'\n",
        "      poetry = 'Поэзия: ' + data.iloc[ind]['text'] + '<eos>'\n",
        "\n",
        "      form = author + keywords + poetry\n",
        "      encodings_dict = tokenizer(form, \n",
        "                                 truncation=True, \n",
        "                                 max_length=max_length, \n",
        "                                 padding=\"max_length\")\n",
        "    \n",
        "      self.input_ids.append(torch.tensor(encodings_dict['input_ids']))\n",
        "      self.attn_masks.append(torch.tensor(encodings_dict['attention_mask']))\n",
        "    \n",
        "  def __len__(self):\n",
        "    return len(self.input_ids)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return {\n",
        "        'input_ids': self.input_ids[idx],\n",
        "        'attention_mask': self.attn_masks[idx]\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "607w_pnJMW5e"
      },
      "outputs": [],
      "source": [
        "train_dataset = myDataset(dataset[dataset['author']=='Маяковский'], tokenizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3H1pAm4Qwmvc"
      },
      "source": [
        "## Add Datacollator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "soPxrXgQpFZQ"
      },
      "outputs": [],
      "source": [
        "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nK8r7CJr743J",
        "outputId": "6168719e-ed27-45e9-a3a2-ee43c702ba6e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([  684,   623,   390,  1936,  1694,    30,  3377, 14817,    16,  6020,\n",
              "            16, 43160,    16, 22182,    16,  8282,   203,  4408,   599,  8253,\n",
              "            30, 37402,   203, 38864, 10252, 34151,   357,   334, 47092, 47092,\n",
              "          8324,    30,   203,   384,   682,  1161,  2559,   323,   203,   338,\n",
              "           230,   338,   230,   338,   230,   338,   230,   338,   230,   338,\n",
              "           230,   338,   230,   338,   230,   338,   230,  4379,   623,  2559,\n",
              "           278,     5,   203, 46249,  6620,   357,   477, 39221,    16,   203,\n",
              "          4379,   623,  2559,   278, 31429,  2661,    18,   203,  4670,   353,\n",
              "          4565,   357,   387,   289,   281,   867,    16,   203,  2824,  6398,\n",
              "          5053,   834,   843,    18,   203, 10269, 33171,   203,   338,   230,\n",
              "           338,   230,   338,   230,   338,   230, 20355, 10252, 10252, 19696,\n",
              "          1139,   203, 32592,  3606,   620,   557,  2869,   282,  2575,  1262,\n",
              "            18,   203, 50259,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]),\n",
              " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0])}"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "train_dataset[950]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kktpNyfnwrPY"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iX2cSazzlm8E"
      },
      "outputs": [],
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=f'.{my_path}checkouts/', #The output directory\n",
        "    overwrite_output_dir=True, #overwrite the content of the output directory\n",
        "    num_train_epochs=65, # number of training epochs\n",
        "    per_device_train_batch_size=4, # batch size for training \n",
        "    warmup_steps=150,#45 number of warmup steps for learning rate scheduler\n",
        "    gradient_accumulation_steps=5, # to make \"virtual\" batch size larger\n",
        "    save_steps = 5000,\n",
        "    fp16=True\n",
        "    )\n",
        "\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    data_collator=data_collator,\n",
        "    train_dataset=train_dataset,\n",
        "    optimizers = (torch.optim.AdamW(model.parameters(),lr=1e-5),None) # Optimizer and lr scheduler\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OVtvq4sLq9EG",
        "outputId": "1b9b3b46-c23d-42d2-dd3e-5410ecb409a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/home/revolt/anaconda3/envs/poetry_gpt3_large/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
            "    There is an imbalance between your GPUs. You may want to exclude GPU 0 which\n",
            "    has less than 75% of the memory or cores of GPU 1. You can do so by setting\n",
            "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
            "    environment variable.\n",
            "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
            "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7zL7BghWwtZH"
      },
      "source": [
        "## Save models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xSNEVeuMFTvO"
      },
      "outputs": [],
      "source": [
        "trainer.save_model(f'./model/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O0DPBfD8aW0A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d3ef1ae-3698-44da-d877-ca2a3f46910c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./tokenizer/tokenizer_config.json',\n",
              " './tokenizer/special_tokens_map.json',\n",
              " './tokenizer/vocab.json',\n",
              " './tokenizer/merges.txt',\n",
              " './tokenizer/added_tokens.json',\n",
              " './tokenizer/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "tokenizer.save_pretrained('./tokenizer')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##load to hugging face"
      ],
      "metadata": {
        "id": "mDop_CDHUAyG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install huggingface_hub\n",
        "!!huggingface-cli login --token {auth_token}"
      ],
      "metadata": {
        "id": "cyUbSs4NTuyw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1453d509-5eb9-41e4-95d7-6933f4e64b80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "Requirement already satisfied: huggingface_hub in /home/revolt/anaconda3/envs/poetry_gpt3_large/lib/python3.9/site-packages (0.14.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /home/revolt/anaconda3/envs/poetry_gpt3_large/lib/python3.9/site-packages (from huggingface_hub) (6.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /home/revolt/anaconda3/envs/poetry_gpt3_large/lib/python3.9/site-packages (from huggingface_hub) (4.65.0)\n",
            "Requirement already satisfied: filelock in /home/revolt/anaconda3/envs/poetry_gpt3_large/lib/python3.9/site-packages (from huggingface_hub) (3.9.0)\n",
            "Requirement already satisfied: requests in /home/revolt/anaconda3/envs/poetry_gpt3_large/lib/python3.9/site-packages (from huggingface_hub) (2.29.0)\n",
            "Requirement already satisfied: fsspec in /home/revolt/anaconda3/envs/poetry_gpt3_large/lib/python3.9/site-packages (from huggingface_hub) (2023.5.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /home/revolt/anaconda3/envs/poetry_gpt3_large/lib/python3.9/site-packages (from huggingface_hub) (23.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/revolt/anaconda3/envs/poetry_gpt3_large/lib/python3.9/site-packages (from huggingface_hub) (4.5.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/revolt/anaconda3/envs/poetry_gpt3_large/lib/python3.9/site-packages (from requests->huggingface_hub) (3.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /home/revolt/anaconda3/envs/poetry_gpt3_large/lib/python3.9/site-packages (from requests->huggingface_hub) (2.0.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/revolt/anaconda3/envs/poetry_gpt3_large/lib/python3.9/site-packages (from requests->huggingface_hub) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/revolt/anaconda3/envs/poetry_gpt3_large/lib/python3.9/site-packages (from requests->huggingface_hub) (2023.5.7)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.',\n",
              " 'Token is valid.',\n",
              " 'Your token has been saved to /home/revolt/.cache/huggingface/token',\n",
              " 'Login successful']"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.push_to_hub('AnyaSchen/rugpt3-large-keywords2poetry')\n",
        "tokenizer.push_to_hub('AnyaSchen/rugpt3-large-keywords2poetry')"
      ],
      "metadata": {
        "id": "Ou2ynJGjTMnx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85795b9c-024a-4ece-dbae-5713060bb80a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CommitInfo(commit_url='https://huggingface.co/AnyaSchen/rugpt3-large-keywords2poetry/commit/c76b450b9e0c9cda363432c7d156e032c68b86bd', commit_message='Upload tokenizer', commit_description='', oid='c76b450b9e0c9cda363432c7d156e032c68b86bd', pr_url=None, pr_revision=None, pr_num=None)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "keo7tQdJwwS8"
      },
      "source": [
        "# Generation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DEVICE = torch.device('cuda') if torch.cuda.is_available() else None"
      ],
      "metadata": {
        "id": "ddFwP9z_v5cf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pJtoWx-WMY6W"
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained('AnyaSchen/rugpt3-large-key2poetry')\n",
        "model = GPT2LMHeadModel.from_pretrained('AnyaSchen/rugpt3-large-key2poetry').to(DEVICE)\n",
        "\n",
        "# or medium size\n",
        "# tokenizer = AutoTokenizer.from_pretrained('AnyaSchen/rugpt3-medium-key2poetry')\n",
        "# model = GPT2LMHeadModel.from_pretrained('AnyaSchen/rugpt3-medium-key2poetry').to(DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E5leSKnXd8t4"
      },
      "outputs": [],
      "source": [
        "inp = '''Автор: Маяковский\n",
        "Ключевые слова: любовь, жизнь, сон\n",
        "Поэзия:'''"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_poetry(input: str, model, num_beams=3):\n",
        "  input = input if len(input) > 0 else tokenizer.bos_token #токен начала предложения\n",
        "  input_ids = tokenizer.encode(input, return_tensors=\"pt\").to(DEVICE)\n",
        "\n",
        "  attention_mask = (input_ids != tokenizer.pad_token_id).int()\n",
        "  with torch.no_grad():\n",
        "        out = model.generate(input_ids,\n",
        "                            do_sample=True,\n",
        "                            num_beams=num_beams,\n",
        "                            temperature=2.0,\n",
        "                            top_p=0.9,\n",
        "                            max_length = 200,\n",
        "                            eos_token_id=tokenizer.eos_token_id,\n",
        "                            bos_token_id=tokenizer.bos_token_id,\n",
        "                            attention_mask = attention_mask,\n",
        "                            ).to(DEVICE)\n",
        "  return tokenizer.batch_decode(out, skip_special_tokens=True)[0]"
      ],
      "metadata": {
        "id": "gwelsPqjFNbQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(generate_poetry(inp, model))"
      ],
      "metadata": {
        "id": "sKFUmDVWFVaR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a555eb14-a460-4838-e5e0-9a3ef33b593c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50259 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Автор: Маяковский\n",
            "Ключевые слова: любовь, жизнь, сон\n",
            "Поэзия: А мне\n",
            "        только снится\n",
            "         настоящая жизнь.\n",
            "Снится\n",
            "         любовь,\n",
            "         настоящая жизнь.\n",
            "Только не пойму —\n",
            "за что\n",
            "       мне такая малость?!\n",
            "Если б длились сны\n",
            "такие же длительные,\n",
            "я б\n",
            "       жилы\n",
            "           из любви к тебе бы\n",
            "алиловым соком исцарапал.\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}